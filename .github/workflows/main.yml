name: CI/CD Pipeline for Spark ETL

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.9"

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Run unit tests
        run: |
          pytest tests/ || echo "No tests found, skipping..."

  deploy:
    needs: build
    runs-on: ubuntu-latest
    environment:
      name: production
      url: ${{ steps.deploy.outputs.web_url }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 'latest'

      - name: Initialize Terraform
        run: |
          cd spoark_task/terraform  # Navigate to the correct directory
          terraform init

      - name: Apply Terraform
        run: |
          cd spoark_task/terraform
          terraform apply -auto-approve

      - name: Deploy Spark Job on Kubernetes
        run: |
          kubectl apply -f kubernetes/spark-deployment.yaml
          kubectl apply -f kubernetes/spark-service.yaml

      - name: Clean up (optional)
        run: |
          cd spoark_task/terraform
          terraform destroy -auto-approve

      - name: Send notification (optional)
        run: |
          echo "Deployment finished successfully"
